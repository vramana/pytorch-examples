{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36823f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/the-verdict.txt', <http.client.HTTPMessage at 0x111128fe0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "       \"the-verdict.txt\")\n",
    "\n",
    "file_path = \"data/the-verdict.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96544d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "Total number of tokens: 4690\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "book_text = open(file_path).read()\n",
    "\n",
    "# with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     raw_book_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(book_text))\n",
    "\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', book_text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "\n",
    "print(\"Total number of tokens:\", len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54f8312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(result))\n",
    "\n",
    "print(len(all_words))\n",
    "\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76e575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {v:k for k,v in self.str_to_int.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        return [self.str_to_int[token] for token in result if token.strip()]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = ' '.join([self.int_to_str[id] for id in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text.strip()\n",
    "\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "\n",
    "ids = tokenizer.encode(\"\\\"It's the last he painted, you know,\\\"\\nMrs. Gisburn said with pardonable pride.\")\n",
    "\n",
    "print(ids)\n",
    "\n",
    "print(tokenizer.decode(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TOKEN = '<|unk|>'\n",
    "END_OF_TEXT_TOKEN = '<|endoftext|>'\n",
    "\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.str_to_int[UNK_TOKEN] = len(vocab)\n",
    "        self.str_to_int[END_OF_TEXT_TOKEN] = len(vocab)\n",
    "        self.int_to_str = {v:k for k,v in self.str_to_int.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        result = [token.strip() for token in result if token.strip()]\n",
    "        result = [token if token in self.str_to_int else UNK_TOKEN for token in result]\n",
    "        return [self.str_to_int[token] for token in result]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = ' '.join([self.int_to_str[id] for id in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text.strip()\n",
    "\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "\n",
    "ids = tokenizer.encode(\"\\\"It's the last he painted, you know,\\\"\\nMrs. Gisburn said with pardonable pride.\")\n",
    "\n",
    "print(ids)\n",
    "\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5879e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9727]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces \"\n",
    "        \"of someunknownPlace.\")\n",
    "\n",
    "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(ids)\n",
    "\n",
    "print(tokenizer.decode(ids))\n",
    "\n",
    "\n",
    "tokenizer.encode(\"made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5be5feaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[   40,   367,  2885,  1464],\n",
       "         [ 1807,  3619,   402,   271],\n",
       "         [10899,  2138,   257,  7026],\n",
       "         [15632,   438,  2016,   257],\n",
       "         [  922,  5891,  1576,   438],\n",
       "         [  568,   340,   373,   645],\n",
       "         [ 1049,  5975,   284,   502],\n",
       "         [  284,  3285,   326,    11]]),\n",
       " tensor([[  367,  2885,  1464,  1807],\n",
       "         [ 3619,   402,   271, 10899],\n",
       "         [ 2138,   257,  7026, 15632],\n",
       "         [  438,  2016,   257,   922],\n",
       "         [ 5891,  1576,   438,   568],\n",
       "         [  340,   373,   645,  1049],\n",
       "         [ 5975,   284,   502,   284],\n",
       "         [ 3285,   326,    11,   287]])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        ids = tokenizer.encode(text)\n",
    "\n",
    "        for i in range(0, len(ids) - max_length, stride):\n",
    "            input_chunk = ids[i:i+max_length]\n",
    "            target_chunk = ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "dataset = GPTDatasetV1(book_text, tokenizer, max_length=4, stride=4)\n",
    "\n",
    "\n",
    "loader = DataLoader(dataset, batch_size = 8, shuffle=False)\n",
    "\n",
    "next(iter(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c76ea1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 3])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "vocab_size = 50357\n",
    "out_dim = 3\n",
    "context_length = 4\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, out_dim)\n",
    "\n",
    "position_embedding_layer = nn.Embedding(context_length, out_dim)\n",
    "\n",
    "position_embeddings = position_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "print(next(iter(loader))[0].shape)\n",
    "\n",
    "embedding_layer(next(iter(loader))[0]).shape\n",
    "\n",
    "position_embeddings.shape\n",
    "\n",
    "inputs, targets = next(iter(loader))\n",
    "\n",
    "token_embeddings = embedding_layer(inputs)\n",
    "\n",
    "input_embeddings = token_embeddings + position_embeddings\n",
    "\n",
    "input_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e0815c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1975, -0.1398,  0.0658],\n",
       "        [-1.6562,  2.8028, -1.6308],\n",
       "        [ 1.0092,  0.1583,  0.3552],\n",
       "        [ 0.7691,  1.2651, -2.3320]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = input_embeddings[0]\n",
    "\n",
    "atten_scores = i @ i.T\n",
    "\n",
    "atten_weights = torch.softmax(atten_scores, dim = -1)\n",
    "\n",
    "all_context_vec = atten_weights @ i \n",
    "\n",
    "all_context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_keys = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_values = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = x @ self.W_query\n",
    "        keys = x @ self.W_keys\n",
    "        values = x @ self.W_values\n",
    "\n",
    "        attention_scores = query @ keys.T\n",
    "        attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim = -1)\n",
    "\n",
    "        context_vec = attention_weights @ values \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8900f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, context_length, dropout, qkv_bias = False) -> None:\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "        self.W_keys = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "        self.W_values = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        query = self.W_query(x)\n",
    "        keys = self.W_keys(x)\n",
    "        values = self.W_values(x)\n",
    "\n",
    "        attention_scores = query @ keys.transpose(1, 2)\n",
    "        attention_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf\n",
    "        )\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores * keys.shape[-1] ** 0.5, dim = -1)\n",
    "        attention_weights = self.dropout(self.attention_weights)\n",
    "\n",
    "        context_values = attention_weights @ values\n",
    "\n",
    "        return context_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionV1(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, context_length, dropout, qkv_bias = False, num_heads = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [\n",
    "                CausalAttention(dim_in, dim_out, context_length, dropout, qkv_bias)\n",
    "                for i in range(num_heads)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "84367d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutliHeadAttentionV2(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, context_length, dropout, qkv_bias = False, num_heads = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.d_out = dim_out \n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert dim_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.head_dim = dim_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "        self.W_keys = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "        self.W_values = nn.Linear(dim_in, dim_out, bias = qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # TODO: Why is the bias left out here?\n",
    "        self.output = nn.Linear(dim_out, dim_out)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, dim_in = x.shape\n",
    "        query = self.W_query(x)\n",
    "        keys = self.W_keys(x)\n",
    "        values = self.W_values(x)\n",
    "\n",
    "        query = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        query = query.transponse(1, 2)\n",
    "        keys = keys.transponse(1, 2)\n",
    "        values = values.transponse(1, 2)\n",
    "\n",
    "        attention_scores = query @ keys.transpose(2, 3)\n",
    "        attention_scores = query.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens],\n",
    "            -torch.inf\n",
    "        )\n",
    "\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / self.head_dim ** 0.5,\n",
    "            dim = - 1\n",
    "        )\n",
    "\n",
    "        context_values = (attention_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_values = context_values.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        context_values = self.output(context_values)\n",
    "\n",
    "        return context_values\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "class DummyTransformer(nn.Module):\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(dim))\n",
    "        self.shift = nn.Parameter(torch.zeroes(dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mean = x.mean(dim = -1, keepdim=True)\n",
    "        var = x.var(dim = -1, unbiased=False, keepdim=True)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * x + self.shift\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformer(cfg) for i in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, seq_len = x.shape\n",
    "\n",
    "        token_embeddings = self.tok_emb(x)\n",
    "        pos_embeddings = self.pos_emb(torch.arange(seq_len, device = x.device))\n",
    "        input_embeddings = token_embeddings + pos_embeddings\n",
    "\n",
    "        input_embeddings = self.drop_emb(input_embeddings)\n",
    "\n",
    "        out = self.trf_blocks(input_embeddings)\n",
    "        out = self.final_norm(out)\n",
    "        logits = self.out_head(out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "027158b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    tokenizer.encode(\"Every effort moves you\"),\n",
    "    tokenizer.encode(\"Every day holds a\")\n",
    "])\n",
    "\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "\n",
    "out = model(x)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bc454649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2961, 0.5166, 0.2517],\n",
      "          [0.6886, 0.0740, 0.8665]]]])\n",
      "tensor([[[[0.3548],\n",
      "          [0.5430]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0587,  0.1618, -0.1031],\n",
       "          [ 0.1455, -0.4690,  0.3235]]]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2,3)\n",
    "x = x.view(1, 1, 2, 3)\n",
    "m = x.mean(dim = -1, keepdim = True)\n",
    "\n",
    "print(x)\n",
    "print(m)\n",
    "\n",
    "x - m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
